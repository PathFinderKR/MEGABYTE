{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Importing Libraries",
   "id": "52896242a346d463"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from einops import rearrange\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Hyperparameters",
   "id": "d389d6b8bf136b0e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Patch size = P\n",
    "# Sequence length = T\n",
    "# Number of patches = K = T/P\n",
    "# global embedding dimension = Dg\n",
    "# local embedding dimension = Dl"
   ],
   "id": "c4ef3d46e76a5317"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "@dataclass\n",
    "class CONFIG:\n",
    "    debug: bool = False\n",
    "    \n",
    "    # Model\n",
    "    vocab_size: int = 512 # 256 characters + 2 special tokens\n",
    "    patch_size: int = 4\n",
    "    sequence_length: int = 1024\n",
    "    num_patch: int = sequence_length // patch_size\n",
    "    flash_attention: bool = False\n",
    "    ## Global model\n",
    "    global_dim: int = 256\n",
    "    global_num_layers: int = 4\n",
    "    global_num_heads: int = 32\n",
    "    global_dim_feedforward: int = 512\n",
    "    global_dropout: float = 0.1\n",
    "    ## Local model\n",
    "    local_dim: int = 256\n",
    "    local_num_layers: int = 4\n",
    "    local_num_heads: int = 8\n",
    "    local_dim_feedforward: int = 512\n",
    "    local_dropout: float = 0.1\n",
    "    ## Special tokens\n",
    "    PAD_ID: int = 256\n",
    "    EOS_ID: int = 257\n",
    "    \n",
    "    # Dataset\n",
    "    validation_size: float = 0.2\n",
    "    \n",
    "    # Device\n",
    "    device: torch.device = None\n",
    "    \n",
    "    # Training\n",
    "    batch_size: int = 2\n",
    "    learning_rate: float = 2e-5\n",
    "    epochs: int = 100\n",
    "    \n",
    "    # Seed\n",
    "    seed: int = 42\n",
    "    \n",
    "config = CONFIG()"
   ],
   "id": "60e93c2e04de8080"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Reproducibility",
   "id": "13c03a9d7d545aa5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    print(f\"Seed: {seed}\")\n",
    "    \n",
    "set_seed(config.seed)"
   ],
   "id": "fce8043802833d27"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Device",
   "id": "aef10a529a5447d3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def configure_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        num_gpu = torch.cuda.device_count()\n",
    "        print(\"> Running on GPU\", end=' | ')\n",
    "        print(\"Num of GPUs: \", num_gpu)\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"> Running on CPU\")\n",
    "    return device\n",
    "\n",
    "CONFIG.device = configure_device()"
   ],
   "id": "39f348183c5da647"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Debug",
   "id": "a405beab399da1ea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c18def8c7828e0ef"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Dataset",
   "id": "fe4f42ed478346e6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "74c5f6ded01e7533"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model",
   "id": "c45df9ae58cabd96"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "6e018774ffb9bf1b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Transformer",
   "id": "925461b57e0467f2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "class TransformerDecoder(nn.Module):",
   "id": "c944cfe7e4be3ee1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## MEGABYTE",
   "id": "4a2c508736e82fc1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class MegaByteDecoder(nn.Module):\n",
    "    def __init__(self, config: CONFIG):\n",
    "        super(MegaByteDecoder, self).__init__()\n",
    "        self.config = config\n",
    "        self.patch_size = config.patch_size\n",
    "        \n",
    "        self.global_embedding = nn.Embedding(config.vocab_size, config.global_dim)\n",
    "        self.global_model = TransformerDecoder(\n",
    "            n_layers=config.global_num_layers,\n",
    "            nhead=config.global_num_heads,\n",
    "            d_model=self.patch_size * config.global_dim,\n",
    "            dim_feedforward=config.global_dim_feedforward,\n",
    "            dropout=config.global_dropout,\n",
    "            flash_attention=config.flash_attention\n",
    "        )\n",
    "        \n",
    "        self.local_embedding = nn.Embedding(config.vocab_size, config.local_dim)\n",
    "        self.local_model = TransformerDecoder(\n",
    "            n_layers=config.local_num_layers,\n",
    "            nhead=config.local_num_heads,\n",
    "            d_model=config.local_dim,\n",
    "            dim_feedforward=config.local_dim_feedforward,\n",
    "            dropout=config.local_dropout,\n",
    "            flash_attention=config.flash_attention\n",
    "        )\n",
    "        \n",
    "        self.pad_id = config.PAD_ID\n",
    "        self.eos_id = config.EOS_ID\n",
    "        \n",
    "    def forward(self, bytes):\n",
    "        bytes_global, bytes_local = self.prepare_input(bytes)\n",
    "        \n",
    "        # Global model\n",
    "        self.global_positional_encoding = PositionalEncoding(config.global_emb_dim)\n",
    "        global_bytes_embedded = self.global_embedding(bytes_global)\n",
    "        global_input = rearrange(global_bytes_embedded, \"b (t p) e -> b t (p e)\", p=self.patch_size)\n",
    "        global_output = self.global_model(global_input)\n",
    "        \n",
    "        # Local model\n",
    "        local_bytes_embedded = self.local_embedding(bytes_local)\n",
    "        self.local_positional_encoding = PositionalEncoding(config.local_emb_dim)\n",
    "        global_output_rearranged = rearrange(global_output, \"b t (p e) -> (b t) p e\", p=self.patch_size)\n",
    "        local_input = local_bytes_embedded + global_output_rearranged\n",
    "        local_output = self.local_model(local_input)\n",
    "        \n",
    "        # Rearrange output\n",
    "        batch_size = bytes_global.shape[0]\n",
    "        x = rearrange(local_output, \"(b t) l v -> b (t l) v\", b=batch_size)\n",
    "        return x\n",
    "        \n",
    "    def prepare_input(self, bytes):\n",
    "        # Padding for global input\n",
    "        padding_global = bytes.new(bytes.shape[0], self.patch_size).fill_(self.pad_id)\n",
    "        bytes_global = torch.cat((padding_global, bytes[:, : -self.patch_size]), -1)\n",
    "        \n",
    "        # Rearrange bytes for local input\n",
    "        bytes_input = rearrange(bytes, \"b (t p) -> (b t) p\", p=self.patch_size)\n",
    "        \n",
    "        # Padding for local input\n",
    "        padding_local = bytes_input.new(bytes_input.shape[0], self.patch_size).fill_(self.pad_id)\n",
    "        bytes_local = torch.cat((padding_local, bytes_input[:, : -self.patch_size]), -1)\n",
    "        \n",
    "        return bytes_global, bytes_local\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def generate(self, bytes):\n",
    "        pass"
   ],
   "id": "b5e980e600f5f2bf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "megabyte = MegaByteDecoder(config)",
   "id": "4b7a8d3a9155e231"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train",
   "id": "7edb7b78f1714e9a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1b495cc61a877c49"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Inference",
   "id": "e70edc36e643819e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3f300a0d3791dfb7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "55f0d720eac83c80"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
