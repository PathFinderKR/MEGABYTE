{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Importing Libraries",
   "id": "52896242a346d463"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from einops import rearrange\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Hyperparameters",
   "id": "d389d6b8bf136b0e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Patch size = P\n",
    "# Sequence length = T\n",
    "# Number of patches = K = T/P\n",
    "# global embedding dimension = Dg\n",
    "# local embedding dimension = Dl"
   ],
   "id": "c4ef3d46e76a5317"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "@dataclass\n",
    "class CONFIG:\n",
    "    debug: bool = False\n",
    "    \n",
    "    # Model\n",
    "    vocab_size: int = 512 # 256 characters + 2 special tokens\n",
    "    patch_size: int = 4\n",
    "    sequence_length: int = 1024\n",
    "    patch_num: int = sequence_length // patch_size\n",
    "    ## Global model\n",
    "    global_emb_dim: int = 512\n",
    "    global_num_layers: int = 4\n",
    "    global_num_heads: int = 32\n",
    "    ## Local model\n",
    "    local_emb_dim: int = 128\n",
    "    local_num_layers: int = 4\n",
    "    local_num_heads: int = 8\n",
    "    ## Special tokens\n",
    "    PAD_ID: int = 256\n",
    "    EOS_ID: int = 257\n",
    "    \n",
    "    # Dataset\n",
    "    validation_size: float = 0.2\n",
    "    \n",
    "    # Device\n",
    "    device: torch.device = None\n",
    "    \n",
    "    # Training\n",
    "    batch_size: int = 2\n",
    "    learning_rate: float = 2e-5\n",
    "    epochs: int = 100\n",
    "    \n",
    "    # Seed\n",
    "    seed: int = 42\n",
    "    \n",
    "config = CONFIG()"
   ],
   "id": "60e93c2e04de8080"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Reproducibility",
   "id": "13c03a9d7d545aa5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    print(f\"Seed: {seed}\")\n",
    "    \n",
    "set_seed(config.seed)"
   ],
   "id": "fce8043802833d27"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Device",
   "id": "aef10a529a5447d3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def configure_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        num_gpu = torch.cuda.device_count()\n",
    "        print(\"> Running on GPU\", end=' | ')\n",
    "        print(\"Num of GPUs: \", num_gpu)\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"> Running on CPU\")\n",
    "    return device\n",
    "\n",
    "CONFIG.device = configure_device()"
   ],
   "id": "39f348183c5da647"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Debug",
   "id": "a405beab399da1ea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c18def8c7828e0ef"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Dataset",
   "id": "fe4f42ed478346e6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "74c5f6ded01e7533"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model",
   "id": "c45df9ae58cabd96"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Transformer",
   "id": "f5563fb4d2b7a739"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "be45b16e3cd5fb43"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## MegaByte",
   "id": "a1bd395955074895"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class GlobalModel(nn.Module):\n",
    "    def __init__(self, config: CONFIG):\n",
    "        super(GlobalModel, self).__init__()\n",
    "        self.config = config\n",
    "        \n",
    "        self.emb_dim = config.global_emb_dim\n",
    "        self.num_layers = config.global_num_layers\n",
    "        self.num_heads = config.global_num_heads\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        pass\n",
    "    "
   ],
   "id": "e38acca4611c3306"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class LocalModel(nn.Module):\n",
    "    def __init__(self, config: CONFIG):\n",
    "        super(LocalModel, self).__init__()\n",
    "        self.config = config\n",
    "        \n",
    "        self.emb_dim = config.local_emb_dim\n",
    "        self.num_layers = config.local_num_layers\n",
    "        self.num_heads = config.local_num_heads\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        pass\n",
    "    "
   ],
   "id": "d509e549412c0b9c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class MegaByteDecoder(nn.Module):\n",
    "    def __init__(self, config: CONFIG):\n",
    "        super(MegaByteDecoder, self).__init__()\n",
    "        self.config = config\n",
    "        self.global_model = GlobalModel(config)\n",
    "        self.local_model = LocalModel(config)\n",
    "        \n",
    "        self.pad_id = config.PAD_ID\n",
    "        \n",
    "    def forward(self, bytes):\n",
    "        pass\n",
    "    \n",
    "    def prepare_input(self, bytes):\n",
    "        # Padding for global input\n",
    "        padding_global = bytes.new(bytes.shape[0], self.patch_size).fill_(self.pad_id)\n",
    "        bytes_global = torch.cat((padding_global, bytes[:, : -self.patch_size]), -1)\n",
    "        \n",
    "        # Rearrange bytes for local input\n",
    "        bytes_input = rearrange(bytes, \"b (t p) -> (b t) p\", p=self.patch_size)\n",
    "        \n",
    "        # Padding for local input\n",
    "        padding_local = bytes_input.new(bytes_input.shape[0], self.patch_size).fill_(self.pad_id)\n",
    "        bytes_local = torch.cat((padding_local, bytes_input[:, : -self.patch_size]), -1)\n",
    "        \n",
    "        return bytes_global, bytes_local\n",
    "        \n",
    "    def generate(self, bytes):\n",
    "        pass"
   ],
   "id": "b5e980e600f5f2bf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "megabyte = MegaByteDecoder(config)",
   "id": "4b7a8d3a9155e231"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train",
   "id": "7edb7b78f1714e9a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1b495cc61a877c49"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Inference",
   "id": "e70edc36e643819e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3f300a0d3791dfb7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "55f0d720eac83c80"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
