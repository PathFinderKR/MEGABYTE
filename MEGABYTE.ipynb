{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Importing Libraries",
   "id": "52896242a346d463"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-12T18:03:52.653279Z",
     "start_time": "2024-10-12T18:03:51.190432Z"
    }
   },
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass\n",
    "from einops import rearrange\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Huggingface\n",
    "import huggingface_hub\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Weights & Biases\n",
    "import wandb"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Hyperparameters",
   "id": "d389d6b8bf136b0e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T18:03:52.656622Z",
     "start_time": "2024-10-12T18:03:52.654414Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Patch size = P\n",
    "# context size = T\n",
    "# Number of patches = K = T/P\n",
    "# global embedding dimension = d_G\n",
    "# local embedding dimension = d_L"
   ],
   "id": "c4ef3d46e76a5317",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T18:03:52.669398Z",
     "start_time": "2024-10-12T18:03:52.657567Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@dataclass\n",
    "class CONFIG:\n",
    "    debug: bool = False\n",
    "    \n",
    "    # Model\n",
    "    V: int = 512  # 258 utf-8 characters + 2 special tokens\n",
    "    P: int = 8\n",
    "    T: int = 8192\n",
    "    K: int = T // P  # Number of patches\n",
    "    \n",
    "    model_name: str = 'MEGABYTE'\n",
    "    model_size: str = 'large'  # 'small' or 'large'\n",
    "    \n",
    "    ## Small\n",
    "    if model_size == 'small':\n",
    "        ### Global model\n",
    "        n_layers_G: int = 6\n",
    "        n_heads_G: int = 4\n",
    "        d_G: int = 128\n",
    "        d_head_G: int = d_G // n_heads_G\n",
    "        d_ff_G: int = d_G * 4\n",
    "        dropout_G: float = 0.1\n",
    "        ### Local model\n",
    "        n_layers_L: int = 4\n",
    "        n_heads_L: int = 4\n",
    "        d_L: int = 64\n",
    "        d_head_L: int = d_L // n_heads_L\n",
    "        d_ff_L: int = d_L * 4\n",
    "        dropout_L: float = 0.1\n",
    "    ### Large\n",
    "    elif model_size == 'large':\n",
    "        ### Global model\n",
    "        n_layers_G: int = 6\n",
    "        n_heads_G: int = 8\n",
    "        d_G: int = 512\n",
    "        d_head_G: int = d_G // n_heads_G\n",
    "        d_ff_G: int = d_G * 4\n",
    "        dropout_G: float = 0.1\n",
    "        ### Local model\n",
    "        n_layers_L: int = 6\n",
    "        n_heads_L: int = 4\n",
    "        d_L: int = 256\n",
    "        d_head_L: int = d_L // n_heads_L\n",
    "        d_ff_L: int = d_L * 4\n",
    "        dropout_L: float = 0.1\n",
    "    \n",
    "    flash_attention: bool = False\n",
    "    \n",
    "    # Vocabulary\n",
    "    PAD_ID: int = 256\n",
    "    EOS_ID: int = 257\n",
    "    \n",
    "    # data\n",
    "    validation_size: float = 0.1\n",
    "    shakespeare_id = \"data/shakespeare.txt\"\n",
    "    wiki_id = \"wikimedia/wikipedia\"\n",
    "    dataset_id = shakespeare_id\n",
    "    \n",
    "    # Device\n",
    "    device: torch.device = None\n",
    "    \n",
    "    # Training\n",
    "    epochs: int = 1\n",
    "    batch_size: int = 4\n",
    "    learning_rate: float = 2e-4\n",
    "    \n",
    "    # Generation\n",
    "    max_len: int = 10000\n",
    "    temperature: float = 1.0\n",
    "    \n",
    "    # Seed\n",
    "    seed: int = 101"
   ],
   "id": "60e93c2e04de8080",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Reproducibility",
   "id": "13c03a9d7d545aa5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T18:03:52.679247Z",
     "start_time": "2024-10-12T18:03:52.670860Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    print(f\"Seed: {seed}\")\n",
    "    \n",
    "set_seed(CONFIG.seed)"
   ],
   "id": "fce8043802833d27",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 101\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Device",
   "id": "aef10a529a5447d3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T18:03:52.938886Z",
     "start_time": "2024-10-12T18:03:52.680289Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def configure_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        num_gpu = torch.cuda.device_count()\n",
    "        print(\"> Running on GPU\", end=' | ')\n",
    "        print(\"Num of GPUs: \", num_gpu)\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "        print(\"> Running on MPS\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"> Running on CPU\")\n",
    "    return device\n",
    "\n",
    "CONFIG.device = configure_device()"
   ],
   "id": "39f348183c5da647",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running on GPU | Num of GPUs:  1\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Debug",
   "id": "a405beab399da1ea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T18:03:52.942238Z",
     "start_time": "2024-10-12T18:03:52.939872Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if CONFIG.debug:\n",
    "    CONFIG.model_size = 'small'\n",
    "    CONFIG.dataset_id = \"data/shakespeare.txt\"\n",
    "    CONFIG.epochs = 1\n",
    "    CONFIG.max_len = 2000"
   ],
   "id": "c18def8c7828e0ef",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# HuggingFace",
   "id": "df7bcab560d43bd6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T18:03:52.949164Z",
     "start_time": "2024-10-12T18:03:52.943154Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#if not CONFIG.debug:\n",
    "#    load_dotenv()\n",
    "#    token = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "#    huggingface_hub.login(token=token, add_to_git_credential=True)"
   ],
   "id": "268ac7fe97641cca",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Weights & Biases",
   "id": "9b1b365edf72fb83"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T18:03:52.955832Z",
     "start_time": "2024-10-12T18:03:52.950191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#if not CONFIG.debug:\n",
    "#    api_key = os.getenv(\"WANDB_API_KEY\")\n",
    "#    wandb.login(key=api_key)\n",
    "#    wandb.init(project=CONFIG.model_name)"
   ],
   "id": "dbc4edc055dd6044",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Dataset",
   "id": "fe4f42ed478346e6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Shakespeare",
   "id": "46bc03f62c2f8dd5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T18:03:52.968927Z",
     "start_time": "2024-10-12T18:03:52.956701Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_shakespeare():\n",
    "    with open(CONFIG.shakespeare_id, 'r') as f:\n",
    "        shakespeare_text = f.read()\n",
    "    return shakespeare_text\n",
    "\n",
    "shakespeare_text = load_shakespeare()"
   ],
   "id": "233545ec5cf61b5e",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T18:03:52.973984Z",
     "start_time": "2024-10-12T18:03:52.970591Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(shakespeare_text[:1000])\n",
    "print(f'Total number of characters in the text: {len(shakespeare_text)}')"
   ],
   "id": "4e9a6798598cc0d5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n",
      "Total number of characters in the text: 1115394\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Wikipedia",
   "id": "969f0de13b5fcfa1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T18:03:52.980811Z",
     "start_time": "2024-10-12T18:03:52.974938Z"
    }
   },
   "cell_type": "code",
   "source": "#wiki_dataset = load_dataset(CONFIG.wiki_id, \"20231101.en\")",
   "id": "194b62588de0b623",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T18:03:52.987492Z",
     "start_time": "2024-10-12T18:03:52.981734Z"
    }
   },
   "cell_type": "code",
   "source": "#wiki_dataset",
   "id": "9dae249d37771db",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T18:03:52.994377Z",
     "start_time": "2024-10-12T18:03:52.988498Z"
    }
   },
   "cell_type": "code",
   "source": "#print(wiki_dataset['train']['text'][0][:1000])",
   "id": "f1293f4ee6ba1747",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Tokenization",
   "id": "505c578a5ddc11b7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T18:03:53.004157Z",
     "start_time": "2024-10-12T18:03:52.995235Z"
    }
   },
   "cell_type": "code",
   "source": [
    "char2int = {chr(i): i for i in range(CONFIG.V)}\n",
    "int2char = {i: chr(i) for i in range(CONFIG.V)}\n",
    "\n",
    "# Add special tokens\n",
    "char2int['<PAD>'] = CONFIG.PAD_ID\n",
    "int2char[CONFIG.PAD_ID] = '<PAD>'\n",
    "char2int['<EOS>'] = CONFIG.EOS_ID\n",
    "int2char[CONFIG.EOS_ID] = '<EOS>'\n",
    "\n",
    "# Encoding and Decoding\n",
    "encode = lambda text: [char2int[c] for c in text]\n",
    "decode = lambda tokens: ''.join([int2char[t] for t in tokens])"
   ],
   "id": "7bf3e3f8386331c9",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T18:03:53.014966Z",
     "start_time": "2024-10-12T18:03:53.005062Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sample_text = \"Hello, World!\" + \"<EOS>\"\n",
    "sample_tokens = encode(sample_text)\n",
    "print(sample_tokens)\n",
    "print(decode(sample_tokens))"
   ],
   "id": "fb83b51bf61a3dba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[72, 101, 108, 108, 111, 44, 32, 87, 111, 114, 108, 100, 33, 60, 69, 79, 83, 62]\n",
      "Hello, World!<EOS>\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Preprocessing",
   "id": "a16efac757bb6828"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T18:03:53.081266Z",
     "start_time": "2024-10-12T18:03:53.015939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess(dataset_id):\n",
    "    if dataset_id == CONFIG.shakespeare_id:\n",
    "        text = load_shakespeare()\n",
    "    elif dataset_id == CONFIG.wiki_id:\n",
    "        text = wiki_dataset['train']['text']\n",
    "    else:\n",
    "        raise ValueError(\"Invalid dataset id\")\n",
    "    tokens = torch.tensor(encode(text), dtype=torch.long)\n",
    "    return tokens\n",
    "\n",
    "dataset_tokens = preprocess(CONFIG.dataset_id)"
   ],
   "id": "9d8a3ca8cb3e0023",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T18:03:53.085118Z",
     "start_time": "2024-10-12T18:03:53.082376Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_validation_split(tokens, validation_size):\n",
    "    train_size = int(len(tokens) * (1 - validation_size))\n",
    "    return tokens[:train_size], tokens[train_size:]\n",
    "\n",
    "train_tokens, validation_tokens = train_validation_split(dataset_tokens, CONFIG.validation_size)"
   ],
   "id": "846af67d59750175",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T18:03:53.092543Z",
     "start_time": "2024-10-12T18:03:53.086065Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f'Train size: {len(train_tokens)}')\n",
    "print(f'Validation size: {len(validation_tokens)}')"
   ],
   "id": "14ac4046d6eb5ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 1003854\n",
      "Validation size: 111540\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T18:03:53.101371Z",
     "start_time": "2024-10-12T18:03:53.093421Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, tokens, context_length):\n",
    "        self.tokens = tokens\n",
    "        self.context_length = context_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.tokens) - self.context_length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.tokens[idx:idx+self.context_length], self.tokens[idx+1:idx+self.context_length+1]"
   ],
   "id": "f8d54da75993d1e",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T18:03:53.111382Z",
     "start_time": "2024-10-12T18:03:53.102586Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_dataloader(train_tokens, validation_tokens, context_length, batch_size):\n",
    "    train_dataset = TextDataset(train_tokens, context_length)\n",
    "    validation_dataset = TextDataset(validation_tokens, context_length)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, validation_loader\n",
    "\n",
    "train_loader, validation_loader = create_dataloader(train_tokens, validation_tokens, CONFIG.T, CONFIG.batch_size)"
   ],
   "id": "bf526d152283658f",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T18:03:53.295270Z",
     "start_time": "2024-10-12T18:03:53.112297Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sample_x, sample_y = next(iter(train_loader))\n",
    "sample_x, sample_y = sample_x.to(CONFIG.device), sample_y.to(CONFIG.device)\n",
    "print(sample_x.shape, sample_y.shape)\n",
    "print(sample_x[0])\n",
    "print(sample_y[0])"
   ],
   "id": "aa19cb9b5d0353c2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8192]) torch.Size([4, 8192])\n",
      "tensor([ 32, 115, 111,  ...,  72,  69,  82], device='cuda:0')\n",
      "tensor([115, 111, 110,  ...,  69,  82,  77], device='cuda:0')\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model",
   "id": "c45df9ae58cabd96"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Transformer",
   "id": "36e603385ec68491"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T18:03:53.301048Z",
     "start_time": "2024-10-12T18:03:53.296238Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CausalSelfAttention(nn.Module):\n",
    "    def __init__(self, d_embed: int, n_heads: int, d_head: int):\n",
    "        super().__init__()\n",
    "        self.d_embed = d_embed\n",
    "        self.n_heads = n_heads\n",
    "        self.d_head = d_head\n",
    "        \n",
    "        self.query = nn.Linear(self.d_embed, self.n_heads * self.d_head, bias=False)\n",
    "        self.key = nn.Linear(self.d_embed, self.n_heads * self.d_head, bias=False)\n",
    "        self.value = nn.Linear(self.d_embed, self.n_heads * self.d_head, bias=False)\n",
    "        self.out = nn.Linear(self.n_heads * self.d_head, self.d_embed, bias=False)\n",
    "        \n",
    "    def forward(self, x):  # [batch_size, context_size, d_embed]\n",
    "        batch_size, context_size, _ = x.size()\n",
    "        q = self.query(x).view(batch_size, context_size, self.n_heads, self.d_head)  # [batch_size, context_size, n_heads, d_head]\n",
    "        k = self.key(x).view(batch_size, context_size, self.n_heads, self.d_head)  # [batch_size, context_size, n_heads, d_head]\n",
    "        v = self.value(x).view(batch_size, context_size, self.n_heads, self.d_head)  # [batch_size, context_size, n_heads, d_head]\n",
    "        \n",
    "        q = q.transpose(1, 2)  # [batch_size, n_heads, context_size, d_head]\n",
    "        k = k.transpose(1, 2)  # [batch_size, n_heads, context_size, d_head]\n",
    "        v = v.transpose(1, 2)  # [batch_size, n_heads, context_size, d_head]\n",
    "        \n",
    "        # Masked Self Attention\n",
    "        mask = torch.triu(torch.ones(context_size, context_size, device=x.device), diagonal=1).bool()  # [context_size, context_size]\n",
    "        mask = mask.view(1, 1, context_size, context_size)  # [1, 1, context_size, context_size]\n",
    "        mask = mask.repeat(batch_size, self.n_heads, 1, 1)  # [batch_size, n_heads, context_size, context_size]\n",
    "        \n",
    "        scores = torch.matmul(q, k.transpose(-2, -1)) / (self.d_head ** 0.5)  # [batch_size, n_heads, context_size, context_size]\n",
    "        scores = scores.masked_fill(mask, float('-inf'))  # [batch_size, n_heads, context_size, context_size]\n",
    "        scores = F.softmax(scores, dim=-1)  # [batch_size, n_heads, context_size, context_size]\n",
    "        \n",
    "        x = torch.matmul(scores, v)  # [batch_size, n_heads, context_size, d_head]\n",
    "        x = x.transpose(1, 2).contiguous().view(batch_size, context_size, self.n_heads * self.d_head)  # [batch_size, context_size, n_heads * d_head]\n",
    "        x = self.out(x)  # [batch_size, context_size, d_embed]\n",
    "        return x"
   ],
   "id": "2c4f95af6a999a2a",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T18:03:53.311847Z",
     "start_time": "2024-10-12T18:03:53.301999Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, d_embed: int, d_ff: int, dropout: float):\n",
    "        super().__init__()\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.fc1 = nn.Linear(d_embed, d_ff, bias=False)\n",
    "        self.fc2 = nn.Linear(d_ff, d_embed, bias=False)\n",
    "        \n",
    "    def forward(self, x):  # [batch_size, context_size, d_embed]\n",
    "        x = F.gelu(self.fc1(x))  # [batch_size, context_size, d_ff]\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.fc2(x)  # [batch_size, context_size, d_embed]\n",
    "        return x"
   ],
   "id": "623ef725d6ec7186",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T18:03:53.321788Z",
     "start_time": "2024-10-12T18:03:53.312872Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, n_heads: int, d_head: int, d_embed: int, d_ff: int, dropout: float):\n",
    "        super().__init__()\n",
    "        self.attention = CausalSelfAttention(d_embed=d_embed, n_heads=n_heads, d_head=d_head)\n",
    "        self.norm1 = nn.LayerNorm(d_embed)\n",
    "        \n",
    "        self.mlp = MLP(d_embed=d_embed, d_ff=d_ff, dropout=dropout)\n",
    "        self.norm2 = nn.LayerNorm(d_embed)\n",
    "        \n",
    "    def forward(self, x):  # [batch_size, context_size, d_embed], [batch_size, num_patches, patch_size * d_embed], [batch_size * num_patches, patch_size, local_d_embed]\n",
    "        x = x + self.attention(self.norm1(x))  # [batch_size, context_size, d_embed], [batch_size, num_patches, patch_size * d_embed], [batch_size * num_patches, patch_size, local_d_embed]\n",
    "        x = x + self.mlp(self.norm2(x))  # [batch_size, context_size, d_embed], [batch_size, num_patches, patch_size * d_embed], [batch_size * num_patches, patch_size, local_d_embed]\n",
    "        return x"
   ],
   "id": "2ca7331d305226e7",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## MEGABYTE",
   "id": "ca7d1e714568e5cb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T18:03:53.330711Z",
     "start_time": "2024-10-12T18:03:53.322781Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PatchEmbedder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.embedding = nn.Embedding(config.V, config.d_G)\n",
    "        self.positional_embedding = nn.Embedding(config.T, config.d_G)\n",
    "        \n",
    "    def forward(self, bytes):  # [batch_size, context_size]\n",
    "        assert self.config.T % self.config.P == 0, \"context size must be divisible by patch size\"\n",
    "        \n",
    "        bytes = self.embedding(bytes) + self.positional_embedding(torch.arange(self.config.T, device=bytes.device))  # [batch_size, context_size, d_embed]\n",
    "        bytes = rearrange(bytes, \"b (k p) d -> b k (p d)\", b=bytes.shape[0], k=self.config.K, p=self.config.P, d=self.config.d_G)  # [batch_size, num_patches, patch_size * d_embed]\n",
    "        return bytes"
   ],
   "id": "aca577b5d80002f1",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T18:03:53.337960Z",
     "start_time": "2024-10-12T18:03:53.331629Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GlobalModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.patch_embedder = PatchEmbedder(config)\n",
    "        self.decoder = Decoder(n_heads=config.n_heads_G, d_head=config.d_head_G, d_embed=config.P*config.d_G, d_ff=config.d_ff_G, dropout=config.dropout_G)\n",
    "        self.linear = nn.Linear(config.d_G, config.d_L, bias=False)\n",
    "        \n",
    "    def forward(self, bytes):  # [batch_size, context_size]\n",
    "        x = self.patch_embedder(bytes)  # [batch_size, num_patches, patch_size * d_embed]\n",
    "        for _ in range(self.config.n_layers_G):\n",
    "            x = self.decoder(x)  # [batch_size, num_patches, patch_size * d_embed]\n",
    "        x = rearrange(x, \"b k (p d) -> (b k) p d\", b=bytes.shape[0], k=self.config.K, p=self.config.P, d=self.config.d_G)  # [batch_size * num_patches, patch_size, d_embed]\n",
    "        x = self.linear(x)  # [batch_size * num_patches, patch_size, local_d_embed]\n",
    "        return x"
   ],
   "id": "4962881ec29397b7",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T18:03:53.348647Z",
     "start_time": "2024-10-12T18:03:53.338976Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LocalModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.embedding = nn.Embedding(config.V, config.d_L)\n",
    "        self.local_transformer = Decoder(n_heads=config.n_heads_L, d_head=config.d_head_L, d_embed=config.d_L, d_ff=config.d_ff_L, dropout=config.dropout_L)\n",
    "        self.linear = nn.Linear(config.d_L, config.V, bias=False)\n",
    "        \n",
    "    def forward(self, local_input, global_output):  # [batch_size * num_patches, patch_size], [batch_size * num_patches, patch_size, local_d_embed]\n",
    "        x = self.embedding(local_input) + global_output  # [batch_size * num_patches, patch_size, local_d_embed]\n",
    "        for _ in range(self.config.n_layers_L):\n",
    "            x = self.local_transformer(x)  # [batch_size * num_patches, patch_size, local_d_embed]\n",
    "        x = self.linear(x)  # [batch_size * num_patches, patch_size, vocab_size]\n",
    "        x = rearrange(x, \"(b k) p v -> b (k p) v\", k=self.config.K, p=self.config.P, v=self.config.V)  # [batch_size, context_size, vocab_size]\n",
    "        return x"
   ],
   "id": "98d05f3337de7d5b",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T18:03:53.358993Z",
     "start_time": "2024-10-12T18:03:53.350509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MEGABYTE(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.global_model = GlobalModel(config)\n",
    "        self.local_model = LocalModel(config)\n",
    "        self.max_len = config.max_len\n",
    "        self.context_size = config.T\n",
    "        self.temperature = config.temperature\n",
    "        \n",
    "    def forward(self, bytes):  # [batch_size, context_size]\n",
    "        global_input, local_input = self.prepare_input(bytes)  # [batch_size, context_size], [batch_size * num_patches, patch_size]\n",
    "        global_output = self.global_model(global_input)  # [batch_size * num_patches, patch_size, local_d_embed]\n",
    "        local_output = self.local_model(local_input, global_output)  # [batch_size, context_size, vocab_size]\n",
    "        return local_output\n",
    "        \n",
    "    def prepare_input(self, bytes):  # [batch_size, context_size]\n",
    "        global_padding = bytes.new(bytes.shape[0], self.config.P).fill_(self.config.PAD_ID)  # [batch_size, patch_size]\n",
    "        global_input = torch.cat((global_padding, bytes[:, :-self.config.P]), dim=-1)  # [batch_size, context_size]\n",
    "        \n",
    "        bytes_input = rearrange(bytes, \"b (k p) -> (b k) p\", p=self.config.P)  # [batch_size * num_patches, patch_size]\n",
    "        local_padding = bytes_input.new(bytes_input.shape[0], 1).fill_(self.config.PAD_ID)  # [patch_size]\n",
    "        local_input = torch.cat((local_padding, bytes_input[:, :-1]), dim=-1)  # [batch_size * num_patches, patch_size]\n",
    "        return global_input, local_input\n",
    "    \n",
    "    def loss(self, bytes, y):  # y: [batch_size, context_size]\n",
    "        y = rearrange(y, \"b t -> (b t)\")  # [batch_size * context_size]\n",
    "        logits = self.forward(bytes)  # [batch_size, context_size, vocab_size]\n",
    "        logits = rearrange(logits, \"b t v -> (b t) v\", v=self.config.V)  # [batch_size * context_size, vocab_size]\n",
    "        return F.cross_entropy(logits, y, ignore_index=self.config.PAD_ID)\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def generate(self, bytes, max_len=None, decode_fn=None):\n",
    "        self.eval()\n",
    "        if max_len is None:\n",
    "            max_len = self.max_len\n",
    "    \n",
    "        for _ in range(max_len - bytes.size(1)):  # x: [batch_size, context]\n",
    "            context = bytes[:, -self.context_size:]  # [batch_size, context_size]\n",
    "            output = self.forward(context)  # [batch_size, context_size, vocab_size]\n",
    "            logits = output[:, -1, :] / self.temperature\n",
    "            next_token = torch.multinomial(F.softmax(logits, dim=-1), num_samples=1).squeeze(-1)  # [batch_size]\n",
    "            bytes = torch.cat((bytes, next_token.unsqueeze(-1)), dim=-1)  # [batch_size, context]\n",
    "    \n",
    "            # Decode token\n",
    "            if decode_fn is not None:\n",
    "                decoded_token = decode_fn([next_token[0].item()])\n",
    "                print(decoded_token, end='', flush=True)\n",
    "                \n",
    "    def get_num_params(self):\n",
    "        return sum(p.numel() for p in self.parameters())\n",
    "    \n",
    "    def get_global_params(self):\n",
    "        return self.global_model.parameters()\n",
    "    \n",
    "    def get_local_params(self):\n",
    "        return self.local_model.parameters()"
   ],
   "id": "625b775dda52818a",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T18:03:53.492460Z",
     "start_time": "2024-10-12T18:03:53.360098Z"
    }
   },
   "cell_type": "code",
   "source": [
    "megabyte = MEGABYTE(CONFIG).to(CONFIG.device)\n",
    "print(megabyte)\n",
    "# number of parameters in millions\n",
    "print(f'Number of parameters: {megabyte.get_num_params() / 1e6:.2f}M')\n",
    "print(f'Number of global parameters: {sum(p.numel() for p in megabyte.get_global_params()) / 1e6:.2f}M')\n",
    "print(f'Number of local parameters: {sum(p.numel() for p in megabyte.get_local_params()) / 1e6:.2f}M')"
   ],
   "id": "733e6e54bcc82764",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEGABYTE(\n",
      "  (global_model): GlobalModel(\n",
      "    (patch_embedder): PatchEmbedder(\n",
      "      (embedding): Embedding(512, 512)\n",
      "      (positional_embedding): Embedding(8192, 512)\n",
      "    )\n",
      "    (decoder): Decoder(\n",
      "      (attention): CausalSelfAttention(\n",
      "        (query): Linear(in_features=4096, out_features=512, bias=False)\n",
      "        (key): Linear(in_features=4096, out_features=512, bias=False)\n",
      "        (value): Linear(in_features=4096, out_features=512, bias=False)\n",
      "        (out): Linear(in_features=512, out_features=4096, bias=False)\n",
      "      )\n",
      "      (norm1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): MLP(\n",
      "        (fc1): Linear(in_features=4096, out_features=2048, bias=False)\n",
      "        (fc2): Linear(in_features=2048, out_features=4096, bias=False)\n",
      "      )\n",
      "      (norm2): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (linear): Linear(in_features=512, out_features=256, bias=False)\n",
      "  )\n",
      "  (local_model): LocalModel(\n",
      "    (embedding): Embedding(512, 256)\n",
      "    (local_transformer): Decoder(\n",
      "      (attention): CausalSelfAttention(\n",
      "        (query): Linear(in_features=256, out_features=256, bias=False)\n",
      "        (key): Linear(in_features=256, out_features=256, bias=False)\n",
      "        (value): Linear(in_features=256, out_features=256, bias=False)\n",
      "        (out): Linear(in_features=256, out_features=256, bias=False)\n",
      "      )\n",
      "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): MLP(\n",
      "        (fc1): Linear(in_features=256, out_features=1024, bias=False)\n",
      "        (fc2): Linear(in_features=1024, out_features=256, bias=False)\n",
      "      )\n",
      "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (linear): Linear(in_features=256, out_features=512, bias=False)\n",
      "  )\n",
      ")\n",
      "Number of parameters: 30.82M\n",
      "Number of global parameters: 29.77M\n",
      "Number of local parameters: 1.05M\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "9403cf8af1b24b0f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T18:03:54.212446Z",
     "start_time": "2024-10-12T18:03:53.493498Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss = megabyte.loss(sample_x, sample_y)\n",
    "print(loss)\n",
    "\n",
    "megabyte.generate(sample_x, max_len=CONFIG.T+1, decode_fn=decode)"
   ],
   "id": "a2e9cd2168cc8fa7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.9080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "s"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Training",
   "id": "7edb7b78f1714e9a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T18:03:54.217080Z",
     "start_time": "2024-10-12T18:03:54.213500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(model):\n",
    "    model = model.to(CONFIG.device)\n",
    "    #criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=CONFIG.learning_rate)\n",
    "    \n",
    "    train_loss = []\n",
    "    validation_loss = []\n",
    "    \n",
    "    for epoch in range(CONFIG.epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for x, y in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{CONFIG.epochs}'):\n",
    "            x, y = x.to(CONFIG.device), y.to(CONFIG.device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = model.loss(x, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        train_loss.append(running_loss / len(train_loader))\n",
    "        print(f'Training Loss: {running_loss / len(train_loader)}')\n",
    "        \n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for x, y in validation_loader:\n",
    "                x, y = x.to(CONFIG.device), y.to(CONFIG.device)\n",
    "                loss = model.loss(x, y)\n",
    "                running_loss += loss.item()\n",
    "                \n",
    "        validation_loss.append(running_loss / len(validation_loader))\n",
    "        print(f'Validation Loss: {running_loss / len(validation_loader)}')\n",
    "        \n",
    "    plt.plot(train_loss, label='Training Loss')\n",
    "    plt.plot(validation_loss, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "id": "1b495cc61a877c49",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T12:10:23.651986Z",
     "start_time": "2024-10-12T18:03:54.217998Z"
    }
   },
   "cell_type": "code",
   "source": "train(model=megabyte)",
   "id": "3d97d7626c626591",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████| 248916/248916 [17:29:39<00:00,  3.95it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.33928113404260507\n",
      "Validation Loss: 8.391607353237616\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAioAAAGwCAYAAACHJU4LAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAxLElEQVR4nO3df3xP9f//8ftrm802e702jFlefubHLOTt1xvvd5LlRxLyTm8tRkpqSKW3fOVXqhGVord+vIsUkS6RT2ghJD9CPjT5UbwZZbN+2GZ+vMZ2vn/4en1bhplt5zm7XS+Xc8k553nOeZxnr7zunfM85+WwLMsSAACAgXzsLgAAAOBSCCoAAMBYBBUAAGAsggoAADAWQQUAABiLoAIAAIxFUAEAAMbys7uAa5Gbm6ujR48qJCREDofD7nIAAEABWJalEydOKDIyUj4+l79mUqqDytGjR+V2u+0uAwAAFMKRI0dUvXr1y7Yp1UElJCRE0vkTdTqdNlcDAAAKIjMzU2632/s9fjmlOqhcuN3jdDoJKgAAlDIFGbbBYFoAAGAsggoAADAWQQUAABirVI9RAQBcm9zcXGVnZ9tdBq4z5cqVk6+vb5Hsi6ACAGVUdna2Dh48qNzcXLtLwXUoNDRUERER1/yeM4IKAJRBlmUpJSVFvr6+crvdV3zpFlBQlmXp1KlTSktLkyRVq1btmvZHUAGAMujcuXM6deqUIiMjFRQUZHc5uM4EBgZKktLS0lSlSpVrug1EhAaAMignJ0eS5O/vb3MluF5dCMBnz569pv0QVACgDON30lBciuqzRVABAADGIqgAAABjEVQAAGVarVq1NH369AK3X7t2rRwOh9LT04utJvx/BBUAQKngcDguO02YMKFQ+926dasGDx5c4PZt27ZVSkqKXC5XoY5XUASi83g8GQBQKqSkpHj/vHDhQo0bN0779u3zLqtQoYL3z5ZlKScnR35+V/6aCw8Pv6o6/P39FRERcVXboPC4ogIAOP+SruxztkyWZRWoxoiICO/kcrnkcDi883v37lVISIhWrFih5s2bKyAgQF9//bUOHDigHj16qGrVqqpQoYJatmypVatW5dnvn2/9OBwO/ec//1GvXr0UFBSkevXqaenSpd71f77SMWfOHIWGhioxMVFRUVGqUKGCunTpkidYnTt3TsOHD1doaKgqVaqkUaNGKS4uTj179iz0v7Pjx4+rf//+CgsLU1BQkLp27aoff/zRuz45OVndu3dXWFiYgoODFR0dreXLl3u3jY2NVXh4uAIDA1WvXj3Nnj270LUUJ66oAAB0+myOGo1LtOXYu5/trCD/ovk6evrppzVt2jTVqVNHYWFhOnLkiO644w49//zzCggI0Ny5c9W9e3ft27dPNWrUuOR+Jk6cqBdffFFTp07VjBkzFBsbq+TkZFWsWDHf9qdOndK0adP0/vvvy8fHR/fff79GjhypefPmSZKmTJmiefPmafbs2YqKitKrr76qJUuWqEOHDoU+1wEDBujHH3/U0qVL5XQ6NWrUKN1xxx3avXu3ypUrp/j4eGVnZ+urr75ScHCwdu/e7b3qNHbsWO3evVsrVqxQ5cqVtX//fp0+fbrQtRQnggoA4Lrx7LPP6vbbb/fOV6xYUU2bNvXOT5o0SYsXL9bSpUs1dOjQS+5nwIAB6tu3ryTphRde0GuvvaYtW7aoS5cu+bY/e/as3njjDdWtW1eSNHToUD377LPe9TNmzNDo0aPVq1cvSdLMmTO9VzcK40JA2bBhg9q2bStJmjdvntxut5YsWaJ77rlHhw8fVu/evdW4cWNJUp06dbzbHz58WM2aNVOLFi0knb+qZCqCCgBAgeV8tfvZzrYdu6hc+OK9ICsrSxMmTNCyZcuUkpKic+fO6fTp0zp8+PBl99OkSRPvn4ODg+V0Or2/XZOfoKAgb0iRzv++zYX2GRkZOnbsmFq1auVd7+vrq+bNmxf6ByH37NkjPz8/tW7d2rusUqVKatCggfbs2SNJGj58uB555BF98cUXiomJUe/evb3n9cgjj6h3797avn27OnXqpJ49e3oDj2kYowIAkMPhUJC/ny1TUb4dNzg4OM/8yJEjtXjxYr3wwgtav369duzYocaNGys7O/uy+ylXrtxF/XO5UJFf+4KOvSkuDz74oP773/+qX79+SkpKUosWLTRjxgxJUteuXZWcnKzHH39cR48eVceOHTVy5Ehb670UggoA4Lq1YcMGDRgwQL169VLjxo0VERGhQ4cOlWgNLpdLVatW1datW73LcnJytH379kLvMyoqSufOndM333zjXfbbb79p3759atSokXeZ2+3WkCFD9Mknn+jJJ5/U22+/7V0XHh6uuLg4ffDBB5o+fbreeuutQtdTnLj1AwC4btWrV0+ffPKJunfvLofDobFjxxb6dsu1GDZsmBISEnTjjTeqYcOGmjFjho4fP16gq0lJSUkKCQnxzjscDjVt2lQ9evTQQw89pDfffFMhISF6+umndcMNN6hHjx6SpBEjRqhr166qX7++jh8/rjVr1igqKkqSNG7cODVv3lzR0dHyeDz67LPPvOtMQ1ABAFy3Xn75ZT3wwANq27atKleurFGjRikzM7PE6xg1apRSU1PVv39/+fr6avDgwercubN8fa88PueWW27JM+/r66tz585p9uzZeuyxx3TnnXcqOztbt9xyi5YvX+69DZWTk6P4+Hj99NNPcjqd6tKli1555RVJ598FM3r0aB06dEiBgYH6+9//rgULFhT9iRcBh2X3TbRrkJmZKZfLpYyMDDmdTrvLAYBS48yZMzp48KBq166t8uXL211OmZObm6uoqCj16dNHkyZNsrucYnG5z9jVfH9zRQUAgGKWnJysL774Qu3bt5fH49HMmTN18OBB3XfffXaXZjwG0wIAUMx8fHw0Z84ctWzZUu3atVNSUpJWrVpl7LgQk3BFBQCAYuZ2u7Vhwwa7yyiVuKICAACMZWtQycnJ0dixY1W7dm0FBgaqbt26mjRpku0vyQEAAGaw9dbPlClTNGvWLL333nuKjo7Wtm3bNHDgQLlcLg0fPtzO0gAAgAFsDSobN25Ujx491K1bN0nnfxTpww8/1JYtW/Jt7/F45PF4vPN2PAsPAABKjq23ftq2bavVq1frhx9+kCTt3LlTX3/9tbp27Zpv+4SEBLlcLu/kdrtLslwAAFDCbA0qTz/9tP75z3+qYcOGKleunJo1a6YRI0YoNjY23/ajR49WRkaGdzpy5EgJVwwAKO1uvfVWjRgxwjtfq1YtTZ8+/bLbOBwOLVmy5JqPXVT7KUtsDSofffSR5s2bp/nz52v79u167733NG3aNL333nv5tg8ICJDT6cwzAQDKhu7du6tLly75rlu/fr0cDoe+++67q97v1q1bNXjw4GstL48JEybo5ptvvmh5SkrKJe8aFJU5c+YoNDS0WI9Rkmwdo/LUU095r6pIUuPGjZWcnKyEhATFxcXZWRoAwDCDBg1S79699dNPP6l69ep51s2ePVstWrRQkyZNrnq/4eHhRVXiFUVERJTYsa4Xtl5ROXXqlHx88pbg6+tryy9bAgDMdueddyo8PFxz5szJszwrK0uLFi3SoEGD9Ntvv6lv37664YYbFBQUpMaNG+vDDz+87H7/fOvnxx9/1C233KLy5curUaNGWrly5UXbjBo1SvXr11dQUJDq1KmjsWPH6uzZs5LOX9GYOHGidu7cKYfDIYfD4a35z7d+kpKSdNtttykwMFCVKlXS4MGDlZWV5V0/YMAA9ezZU9OmTVO1atVUqVIlxcfHe49VGIcPH1aPHj1UoUIFOZ1O9enTR8eOHfOu37lzpzp06KCQkBA5nU41b95c27Ztk3T+pwC6d++usLAwBQcHKzo6WsuXLy90LQVh6xWV7t276/nnn1eNGjUUHR2t//3f//X+0iUAoARZlnT2lD3HLhckORxXbObn56f+/ftrzpw5GjNmjBz/b5tFixYpJydHffv2VVZWlpo3b65Ro0bJ6XRq2bJl6tevn+rWratWrVpd8Ri5ubm6++67VbVqVX3zzTfKyMjIM57lgpCQEM2ZM0eRkZFKSkrSQw89pJCQEP3rX//Svffeq127dunzzz/XqlWrJEkul+uifZw8eVKdO3dWmzZttHXrVqWlpenBBx/U0KFD84SxNWvWqFq1alqzZo3279+ve++9VzfffLMeeuihK55Pfud3IaSsW7dO586dU3x8vO69916tXbtWkhQbG6tmzZpp1qxZ8vX11Y4dO7y/yBwfH6/s7Gx99dVXCg4O1u7du1WhQoWrruNq2BpUZsyYobFjx+rRRx9VWlqaIiMj9fDDD2vcuHF2lgUAZc/ZU9ILkfYc+/8clfyDC9T0gQce0NSpU7Vu3Trdeuutks7f9undu7f3idCRI0d62w8bNkyJiYn66KOPChRUVq1apb179yoxMVGRkef744UXXrhoXMkzzzzj/XOtWrU0cuRILViwQP/6178UGBioChUqyM/P77K3eubPn68zZ85o7ty5Cg4+f/4zZ85U9+7dNWXKFFWtWlWSFBYWppkzZ8rX11cNGzZUt27dtHr16kIFldWrVyspKUkHDx70Pjk7d+5cRUdHa+vWrWrZsqUOHz6sp556Sg0bNpQk1atXz7v94cOH1bt3bzVu3FiSVKdOnauu4WrZeusnJCRE06dPV3Jysk6fPq0DBw7oueeek7+/v51lAQAM1bBhQ7Vt21bvvvuuJGn//v1av369Bg0aJOn8G88nTZqkxo0bq2LFiqpQoYISExN1+PDhAu1/z549crvd3pAiSW3atLmo3cKFC9WuXTtFRESoQoUKeuaZZwp8jD8eq2nTpt6QIknt2rVTbm6u9u3b510WHR0tX19f73y1atWUlpZ2Vcf64zHdbnee13s0atRIoaGh2rNnjyTpiSee0IMPPqiYmBhNnjxZBw4c8LYdPny4nnvuObVr107jx48v1ODlq8WPEgIAzt9++T9H7Tv2VRg0aJCGDRum119/XbNnz1bdunXVvn17SdLUqVP16quvavr06WrcuLGCg4M1YsQIZWdnF1m5mzZtUmxsrCZOnKjOnTvL5XJpwYIFeumll4rsGH904bbLBQ6Ho1jHck6YMEH33Xefli1bphUrVmj8+PFasGCBevXqpQcffFCdO3fWsmXL9MUXXyghIUEvvfSShg0bVmz18KOEAIDzY0T8g+2ZCjA+5Y/69OkjHx8fzZ8/X3PnztUDDzzgHa+yYcMG9ejRQ/fff7+aNm2qOnXqeF8qWhBRUVE6cuSIUlJSvMs2b96cp83GjRtVs2ZNjRkzRi1atFC9evWUnJycp42/v79ycnKueKydO3fq5MmT3mUbNmyQj4+PGjRoUOCar8aF8/vje8h2796t9PR0NWrUyLusfv36evzxx/XFF1/o7rvv1uzZs73r3G63hgwZok8++URPPvmk3n777WKp9QKCCgCgVKlQoYLuvfdejR49WikpKRowYIB3Xb169bRy5Upt3LhRe/bs0cMPP5zniZYriYmJUf369RUXF6edO3dq/fr1GjNmTJ429erV0+HDh7VgwQIdOHBAr732mhYvXpynTa1atXTw4EHt2LFDv/76a56ff7kgNjZW5cuXV1xcnHbt2qU1a9Zo2LBh6tevn3d8SmHl5ORox44deaY9e/YoJiZGjRs3VmxsrLZv364tW7aof//+at++vVq0aKHTp09r6NChWrt2rZKTk7VhwwZt3bpVUVFRkqQRI0YoMTFRBw8e1Pbt27VmzRrvuuJCUAEAlDqDBg3S8ePH1blz5zzjSZ555hn95S9/UefOnXXrrbcqIiJCPXv2LPB+fXx8tHjxYp0+fVqtWrXSgw8+qOeffz5Pm7vuukuPP/64hg4dqptvvlkbN27U2LFj87Tp3bu3unTpog4dOig8PDzfR6SDgoKUmJio33//XS1bttQ//vEPdezYUTNnzry6zshHVlaWmjVrlmfq3r27HA6HPv30U4WFhemWW25RTEyM6tSpo4ULF0o6/4qQ3377Tf3791f9+vXVp08fde3aVRMnTpR0PgDFx8crKipKXbp0Uf369fXvf//7muu9HIdlWVaxHqEYZWZmyuVyKSMjg7fUAsBVOHPmjA4ePKjatWurfPnydpeD69DlPmNX8/3NFRUAAGAsggoAADAWQQUAABiLoAIAAIxFUAGAMqwUP08BwxXVZ4ugAgBl0IVXshflG1uBPzp16vyPXP75zbpXi1foA0AZ5Ofnp6CgIP3yyy8qV66cfHz4/1YUDcuydOrUKaWlpSk0NDTP7xQVBkEFAMogh8OhatWq6eDBgxe9/h0oCqGhoZf99eiCIqgAQBnl7++vevXqcfsHRa5cuXLXfCXlAoIKAJRhPj4+vJkWRuOmJAAAMBZBBQAAGIugAgAAjEVQAQAAxiKoAAAAYxFUAACAsQgqAADAWAQVAABgLIIKAAAwFkEFAAAYi6ACAACMRVABAADGIqgAAABjEVQAAICxCCoAAMBYtgaVWrVqyeFwXDTFx8fbWRYAADCEn50H37p1q3Jycrzzu3bt0u2336577rnHxqoAAIApbA0q4eHheeYnT56sunXrqn379jZVBAAATGJrUPmj7OxsffDBB3riiSfkcDjybePxeOTxeLzzmZmZJVUeAACwgTGDaZcsWaL09HQNGDDgkm0SEhLkcrm8k9vtLrkCAQBAiXNYlmXZXYQkde7cWf7+/vqf//mfS7bJ74qK2+1WRkaGnE5nSZQJAACuUWZmplwuV4G+v4249ZOcnKxVq1bpk08+uWy7gIAABQQElFBVAADAbkbc+pk9e7aqVKmibt262V0KAAAwiO1BJTc3V7Nnz1ZcXJz8/Iy4wAMAAAxhe1BZtWqVDh8+rAceeMDuUgAAgGFsv4TRqVMnGTKeFwAAGMb2KyoAAACXQlABAADGIqgAAABjEVQAAICxCCoAAMBYBBUAAGAsggoAADAWQQUAABiLoAIAAIxFUAEAAMYiqAAAAGMRVAAAgLEIKgAAwFgEFQAAYCyCCgAAMBZBBQAAGIugAgAAjEVQAQAAxiKoAAAAYxFUAACAsQgqAADAWAQVAABgLIIKAAAwFkEFAAAYi6ACAACMRVABAADGIqgAAABjEVQAAICxCCoAAMBYBBUAAGAsggoAADCW7UHl559/1v33369KlSopMDBQjRs31rZt2+wuCwAAGMDPzoMfP35c7dq1U4cOHbRixQqFh4frxx9/VFhYmJ1lAQAAQ9gaVKZMmSK3263Zs2d7l9WuXdvGigAAgElsvfWzdOlStWjRQvfcc4+qVKmiZs2a6e23375ke4/Ho8zMzDwTAAC4ftkaVP773/9q1qxZqlevnhITE/XII49o+PDheu+99/Jtn5CQIJfL5Z3cbncJVwwAAEqSw7Isy66D+/v7q0WLFtq4caN32fDhw7V161Zt2rTpovYej0cej8c7n5mZKbfbrYyMDDmdzhKpGQAAXJvMzEy5XK4CfX/bekWlWrVqatSoUZ5lUVFROnz4cL7tAwIC5HQ680wAAOD6ZWtQadeunfbt25dn2Q8//KCaNWvaVBEAADCJrUHl8ccf1+bNm/XCCy9o//79mj9/vt566y3Fx8fbWRYAADCErUGlZcuWWrx4sT788EPddNNNmjRpkqZPn67Y2Fg7ywIAAIawdTDttbqawTgAAMAMpWYwLQAAwOUQVAAAgLEIKgAAwFgEFQAAYCyCCgAAMBZBBQAAGIugAgAAjEVQAQAAxiKoAAAAYxFUAACAsQgqAADAWAQVAABgLIIKAAAwFkEFAAAYi6ACAACMRVABAADGIqgAAABjEVQAAICxCCoAAMBYBBUAAGAsggoAADAWQQUAABiLoAIAAIxFUAEAAMYiqAAAAGMRVAAAgLEIKgAAwFgEFQAAYCyCCgAAMBZBBQAAGIugAgAAjGVrUJkwYYIcDkeeqWHDhnaWBAAADOJndwHR0dFatWqVd97Pz/aSAACAIWxPBX5+foqIiChQW4/HI4/H453PzMwsrrIAAIABbB+j8uOPPyoyMlJ16tRRbGysDh8+fMm2CQkJcrlc3sntdpdgpQAAoKQ5LMuy7Dr4ihUrlJWVpQYNGiglJUUTJ07Uzz//rF27dikkJOSi9vldUXG73crIyJDT6SzJ0gEAQCFlZmbK5XIV6Pvb1qDyZ+np6apZs6ZefvllDRo06Irtr+ZEAQCAGa7m+9v2Wz9/FBoaqvr162v//v12lwIAAAxgVFDJysrSgQMHVK1aNbtLAQAABrA1qIwcOVLr1q3ToUOHtHHjRvXq1Uu+vr7q27evnWUBAABD2Pp48k8//aS+ffvqt99+U3h4uP72t79p8+bNCg8Pt7MsAABgCFuDyoIFC+w8PAAAMJxRY1QAAAD+iKACAACMRVABAADGIqgAAABjEVQAAICxCCoAAMBYBBUAAGAsggoAADBWoYLKkSNH9NNPP3nnt2zZohEjRuitt94qssIAAAAKFVTuu+8+rVmzRpKUmpqq22+/XVu2bNGYMWP07LPPFmmBAACg7CpUUNm1a5datWolSfroo4900003aePGjZo3b57mzJlTlPUBAIAyrFBB5ezZswoICJAkrVq1SnfddZckqWHDhkpJSSm66gAAQJlWqKASHR2tN954Q+vXr9fKlSvVpUsXSdLRo0dVqVKlIi0QAACUXYUKKlOmTNGbb76pW2+9VX379lXTpk0lSUuXLvXeEgIAALhWDsuyrMJsmJOTo8zMTIWFhXmXHTp0SEFBQapSpUqRFXg5mZmZcrlcysjIkNPpLJFjAgCAa3M139+FuqJy+vRpeTweb0hJTk7W9OnTtW/fvhILKQAA4PpXqKDSo0cPzZ07V5KUnp6u1q1b66WXXlLPnj01a9asIi0QAACUXYUKKtu3b9ff//53SdLHH3+sqlWrKjk5WXPnztVrr71WpAUCAICyq1BB5dSpUwoJCZEkffHFF7r77rvl4+Ojv/71r0pOTi7SAgEAQNlVqKBy4403asmSJTpy5IgSExPVqVMnSVJaWhqDWgEAQJEpVFAZN26cRo4cqVq1aqlVq1Zq06aNpPNXV5o1a1akBQIAgLKr0I8np6amKiUlRU2bNpWPz/m8s2XLFjmdTjVs2LBIi7wUHk8GAKD0uZrvb7/CHiQiIkIRERHeX1GuXr06L3sDAABFqlC3fnJzc/Xss8/K5XKpZs2aqlmzpkJDQzVp0iTl5uYWdY0AAKCMKtQVlTFjxuidd97R5MmT1a5dO0nS119/rQkTJujMmTN6/vnni7RIAABQNhVqjEpkZKTeeOMN768mX/Dpp5/q0Ucf1c8//1xkBV4OY1QAACh9iv0V+r///nu+A2YbNmyo33//vTC7BAAAuEihgkrTpk01c+bMi5bPnDlTTZo0ueaiAAAApEKOUXnxxRfVrVs3rVq1yvsOlU2bNunIkSNavnx5kRYIAADKrkJdUWnfvr1++OEH9erVS+np6UpPT9fdd9+t77//Xu+//35R1wgAAMqoQr/wLT87d+7UX/7yF+Xk5BTVLi+LwbQAAJQ+xT6YtjhMnjxZDodDI0aMsLsUAABgCCOCytatW/Xmm28yEBcAAORhe1DJyspSbGys3n77bYWFhV22rcfjUWZmZp4JAABcv67qqZ+77777suvT09OvuoD4+Hh169ZNMTExeu655y7bNiEhQRMnTrzqYwAAgNLpqoKKy+W64vr+/fsXeH8LFizQ9u3btXXr1gK1Hz16tJ544gnvfGZmptxud4GPBwAASperCiqzZ88usgMfOXJEjz32mFauXKny5csXaJuAgAAFBAQUWQ0AAMBsRfp48tVYsmSJevXqJV9fX++ynJwcORwO+fj4yOPx5FmXHx5PBgCg9Lma7+9CvZm2KHTs2FFJSUl5lg0cOFANGzbUqFGjrhhSAADA9c+2oBISEqKbbropz7Lg4GBVqlTpouUAAKBssv3xZAAAgEux7YpKftauXWt3CQAAwCBcUQEAAMYiqAAAAGMRVAAAgLEIKgAAwFgEFQAAYCyCCgAAMBZBBQAAGIugAgAAjEVQAQAAxiKoAAAAYxFUAACAsQgqAADAWAQVAABgLIIKAAAwFkEFAAAYi6ACAACMRVABAADGIqgAAABjEVQAAICxCCoAAMBYBBUAAGAsggoAADAWQQUAABiLoAIAAIxFUAEAAMYiqAAAAGMRVAAAgLEIKgAAwFgEFQAAYCyCCgAAMJatQWXWrFlq0qSJnE6nnE6n2rRpoxUrVthZEgAAMIitQaV69eqaPHmyvv32W23btk233XabevTooe+//97OsgAAgCEclmVZdhfxRxUrVtTUqVM1aNCgK7bNzMyUy+VSRkaGnE5nCVQHAACu1dV8f/uVUE1XlJOTo0WLFunkyZNq06ZNvm08Ho88Ho93PjMzs6TKAwAANrB9MG1SUpIqVKiggIAADRkyRIsXL1ajRo3ybZuQkCCXy+Wd3G53CVcLAABKku23frKzs3X48GFlZGTo448/1n/+8x+tW7cu37CS3xUVt9vNrR8AAEqRq7n1Y3tQ+bOYmBjVrVtXb7755hXbMkYFAIDS52q+v22/9fNnubm5ea6aAACAssvWwbSjR49W165dVaNGDZ04cULz58/X2rVrlZiYaGdZAADAELYGlbS0NPXv318pKSlyuVxq0qSJEhMTdfvtt9tZFgAAMIStQeWdd96x8/AAAMBwxo1RAQAAuICgAgAAjEVQAQAAxiKoAAAAYxFUAACAsQgqAADAWAQVAABgLIIKAAAwFkEFAAAYi6ACAACMRVABAADGIqgAAABjEVQAAICxCCoAAMBYBBUAAGAsggoAADAWQQUAABiLoAIAAIxFUAEAAMYiqAAAAGMRVAAAgLEIKgAAwFgEFQAAYCyCCgAAMBZBBQAAGIugAgAAjEVQAQAAxiKoAAAAYxFUAACAsQgqAADAWAQVAABgLFuDSkJCglq2bKmQkBBVqVJFPXv21L59++wsCQAAGMTWoLJu3TrFx8dr8+bNWrlypc6ePatOnTrp5MmTdpYFAAAM4bAsy7K7iAt++eUXValSRevWrdMtt9xyxfaZmZlyuVzKyMiQ0+ksgQoBAMC1uprvb78SqqlAMjIyJEkVK1bMd73H45HH4/HOZ2ZmlkhdAADAHsYMps3NzdWIESPUrl073XTTTfm2SUhIkMvl8k5ut7uEqwQAACXJmFs/jzzyiFasWKGvv/5a1atXz7dNfldU3G43t34AAChFSt2tn6FDh+qzzz7TV199dcmQIkkBAQEKCAgowcoAAICdbA0qlmVp2LBhWrx4sdauXavatWvbWQ4AADCMrUElPj5e8+fP16effqqQkBClpqZKklwulwIDA+0sDQAAGMDWMSoOhyPf5bNnz9aAAQOuuD2PJwMAUPqUmjEqhozjBQAAhjLm8WQAAIA/I6gAAABjEVQAAICxCCoAAMBYBBUAAGAsggoAADAWQQUAABiLoAIAAIxFUAEAAMYiqAAAAGMRVAAAgLEIKgAAwFgEFQAAYCyCCgAAMBZBBQAAGIugAgAAjEVQAQAAxiKoAAAAYxFUAACAsQgqAADAWAQVAABgLIIKAAAwFkEFAAAYi6ACAACMRVABAADGIqgAAABjEVQAAICxCCoAAMBYBBUAAGAsggoAADAWQQUAABjL1qDy1VdfqXv37oqMjJTD4dCSJUvsLAcAABjG1qBy8uRJNW3aVK+//rqdZQAAAEP52Xnwrl27qmvXrgVu7/F45PF4vPOZmZnFURYAADBEqRqjkpCQIJfL5Z3cbrfdJQEAgGJUqoLK6NGjlZGR4Z2OHDlid0kAAKAY2Xrr52oFBAQoICDA7jIAAEAJKVVXVAAAQNlCUAEAAMay9dZPVlaW9u/f750/ePCgduzYoYoVK6pGjRo2VgYAAExga1DZtm2bOnTo4J1/4oknJElxcXGaM2eOTVUBAABT2BpUbr31VlmWZWcJAADAYIxRAQAAxiKoAAAAYxFUAACAsQgqAADAWAQVAABgLIIKAAAwFkEFAAAYi6ACAACMRVABAADGIqgAAABjEVQAAICxCCoAAMBYBBUAAGAsggoAADAWQQUAABiLoAIAAIxFUAEAAMYiqAAAAGMRVAAAgLEIKgAAwFgEFQAAYCyCCgAAMBZBBQAAGIugAgAAjEVQAQAAxiKoAAAAYxFUAACAsQgqAADAWAQVAABgLIIKAAAwlhFB5fXXX1etWrVUvnx5tW7dWlu2bLG7JAAAYADbg8rChQv1xBNPaPz48dq+fbuaNm2qzp07Ky0tze7SAACAzWwPKi+//LIeeughDRw4UI0aNdIbb7yhoKAgvfvuu3aXBgAAbGZrUMnOzta3336rmJgY7zIfHx/FxMRo06ZNF7X3eDzKzMzMMwEAgOuXrUHl119/VU5OjqpWrZpnedWqVZWamnpR+4SEBLlcLu/kdrtLqlQAAGAD22/9XI3Ro0crIyPDOx05csTukgAAQDHys/PglStXlq+vr44dO5Zn+bFjxxQREXFR+4CAAAUEBHjnLcuSJG4BAQBQilz43r7wPX45tgYVf39/NW/eXKtXr1bPnj0lSbm5uVq9erWGDh16xe1PnDghSdwCAgCgFDpx4oRcLtdl29gaVCTpiSeeUFxcnFq0aKFWrVpp+vTpOnnypAYOHHjFbSMjI3XkyBGFhITI4XCUQLVmy8zMlNvt1pEjR+R0Ou0u57pFP5cM+rlk0M8lh77+/yzL0okTJxQZGXnFtrYHlXvvvVe//PKLxo0bp9TUVN188836/PPPLxpgmx8fHx9Vr169BKosXZxOZ5n/j6Ak0M8lg34uGfRzyaGvz7vSlZQLbA8qkjR06NAC3eoBAABlS6l66gcAAJQtBJXrSEBAgMaPH5/nySgUPfq5ZNDPJYN+Ljn0deE4rII8GwQAAGADrqgAAABjEVQAAICxCCoAAMBYBBUAAGAsgkop8vvvvys2NlZOp1OhoaEaNGiQsrKyLrvNmTNnFB8fr0qVKqlChQrq3bv3Rb+tdMFvv/2m6tWry+FwKD09vRjOoHQojn7euXOn+vbtK7fbrcDAQEVFRenVV18t7lMxzuuvv65atWqpfPnyat26tbZs2XLZ9osWLVLDhg1Vvnx5NW7cWMuXL8+z3rIsjRs3TtWqVVNgYKBiYmL0448/FucplApF2c9nz57VqFGj1LhxYwUHBysyMlL9+/fX0aNHi/s0jFfUn+c/GjJkiBwOh6ZPn17EVZdCFkqNLl26WE2bNrU2b95srV+/3rrxxhutvn37XnabIUOGWG6321q9erW1bds2669//avVtm3bfNv26NHD6tq1qyXJOn78eDGcQelQHP38zjvvWMOHD7fWrl1rHThwwHr//fetwMBAa8aMGcV9OsZYsGCB5e/vb7377rvW999/bz300ENWaGiodezYsXzbb9iwwfL19bVefPFFa/fu3dYzzzxjlStXzkpKSvK2mTx5suVyuawlS5ZYO3futO666y6rdu3a1unTp0vqtIxT1P2cnp5uxcTEWAsXLrT27t1rbdq0yWrVqpXVvHnzkjwt4xTH5/mCTz75xGratKkVGRlpvfLKK8V8JuYjqJQSu3fvtiRZW7du9S5bsWKF5XA4rJ9//jnfbdLT061y5cpZixYt8i7bs2ePJcnatGlTnrb//ve/rfbt21urV68u00GluPv5jx599FGrQ4cORVe84Vq1amXFx8d753NycqzIyEgrISEh3/Z9+vSxunXrlmdZ69atrYcfftiyLMvKzc21IiIirKlTp3rXp6enWwEBAdaHH35YDGdQOhR1P+dny5YtliQrOTm5aIouhYqrn3/66SfrhhtusHbt2mXVrFmToGJZFrd+SolNmzYpNDRULVq08C6LiYmRj4+Pvvnmm3y3+fbbb3X27FnFxMR4lzVs2FA1atTQpk2bvMt2796tZ599VnPnzpWPT9n+SBRnP/9ZRkaGKlasWHTFGyw7O1vffvttnj7y8fFRTEzMJfto06ZNedpLUufOnb3tDx48qNTU1DxtXC6XWrdufdl+v54VRz/nJyMjQw6HQ6GhoUVSd2lTXP2cm5urfv366amnnlJ0dHTxFF8Kle1vpVIkNTVVVapUybPMz89PFStWVGpq6iW38ff3v+gvk6pVq3q38Xg86tu3r6ZOnaoaNWoUS+2lSXH1859t3LhRCxcu1ODBg4ukbtP9+uuvysnJuejHRi/XR6mpqZdtf+GfV7PP611x9POfnTlzRqNGjVLfvn3L7A/rFVc/T5kyRX5+fho+fHjRF12KEVRs9vTTT8vhcFx22rt3b7Edf/To0YqKitL9999fbMcwgd39/Ee7du1Sjx49NH78eHXq1KlEjgkUhbNnz6pPnz6yLEuzZs2yu5zryrfffqtXX31Vc+bMkcPhsLscoxjx68ll2ZNPPqkBAwZctk2dOnUUERGhtLS0PMvPnTun33//XREREfluFxERoezsbKWnp+f5v/1jx455t/nyyy+VlJSkjz/+WNL5pygkqXLlyhozZowmTpxYyDMzi939fMHu3bvVsWNHDR48WM8880yhzqU0qly5snx9fS964iy/ProgIiLisu0v/PPYsWOqVq1anjY333xzEVZfehRHP19wIaQkJyfryy+/LLNXU6Ti6ef169crLS0tz5XtnJwcPfnkk5o+fboOHTpUtCdRmtg9SAYFc2GQ57Zt27zLEhMTCzTI8+OPP/Yu27t3b55Bnvv377eSkpK807vvvmtJsjZu3HjJ0evXs+LqZ8uyrF27dllVqlSxnnrqqeI7AYO1atXKGjp0qHc+JyfHuuGGGy47+PDOO+/Ms6xNmzYXDaadNm2ad31GRgaDaYu4ny3LsrKzs62ePXta0dHRVlpaWvEUXsoUdT//+uuvef4uTkpKsiIjI61Ro0ZZe/fuLb4TKQUIKqVIly5drGbNmlnffPON9fXXX1v16tXL89jsTz/9ZDVo0MD65ptvvMuGDBli1ahRw/ryyy+tbdu2WW3atLHatGlzyWOsWbOmTD/1Y1nF089JSUlWeHi4df/991spKSneqSz9pb9gwQIrICDAmjNnjrV7925r8ODBVmhoqJWammpZlmX169fPevrpp73tN2zYYPn5+VnTpk2z9uzZY40fPz7fx5NDQ0OtTz/91Pruu++sHj168HhyEfdzdna2ddddd1nVq1e3duzYkefz6/F4bDlHExTH5/nPeOrnPIJKKfLbb79Zffv2tSpUqGA5nU5r4MCB1okTJ7zrDx48aEmy1qxZ4112+vRp69FHH7XCwsKsoKAgq1evXlZKSsolj0FQKZ5+Hj9+vCXpoqlmzZoleGb2mzFjhlWjRg3L39/fatWqlbV582bvuvbt21txcXF52n/00UdW/fr1LX9/fys6OtpatmxZnvW5ubnW2LFjrapVq1oBAQFWx44drX379pXEqRitKPv5wuc9v+mP/w2URUX9ef4zgsp5Dsv6f4MSAAAADMNTPwAAwFgEFQAAYCyCCgAAMBZBBQAAGIugAgAAjEVQAQAAxiKoAAAAYxFUAACAsQgqAEo9h8OhJUuW2F0GgGJAUAFwTQYMGCCHw3HR1KVLF7tLA3Ad8LO7AAClX5cuXTR79uw8ywICAmyqBsD1hCsqAK5ZQECAIiIi8kxhYWGSzt+WmTVrlrp27arAwEDVqVNHH3/8cZ7tk5KSdNtttykwMFCVKlXS4MGDlZWVlafNu+++q+joaAUEBKhatWoaOnRonvW//vqrevXqpaCgINWrV09Lly71rjt+/LhiY2MVHh6uwMBA1atX76JgBcBMBBUAxW7s2LHq3bu3du7cqdjYWP3zn//Unj17JEknT55U586dFRYWpq1bt2rRokVatWpVniAya9YsxcfHa/DgwUpKStLSpUt144035jnGxIkT1adPH3333Xe64447FBsbq99//917/N27d2vFihXas2ePZs2apcqVK5dcBwAoPLt/vhlA6RYXF2f5+vpawcHBeabnn3/esizLkmQNGTIkzzatW7e2HnnkEcuyLOutt96ywsLCrKysLO/6ZcuWWT4+PlZqaqplWZYVGRlpjRkz5pI1SLKeeeYZ73xWVpYlyVqxYoVlWZbVvXt3a+DAgUVzwgBKFGNUAFyzDh06aNasWXmWVaxY0fvnNm3a5FnXpk0b7dixQ5K0Z88eNW3aVMHBwd717dq1U25urvbt2yeHw6GjR4+qY8eOl62hSZMm3j8HBwfL6XQqLS1NkvTII4+od+/e2r59uzp16qSePXuqbdu2hTpXACWLoALgmgUHB190K6aoBAYGFqhduXLl8sw7HA7l5uZKkrp27ark5GQtX75cK1euVMeOHRUfH69p06YVeb0AihZjVAAUu82bN180HxUVJUmKiorSzp07dfLkSe/6DRs2yMfHRw0aNFBISIhq1aql1atXX1MN4eHhiouL0wcffKDp06frrbfeuqb9ASgZXFEBcM08Ho9SU1PzLPPz8/MOWF20aJFatGihv/3tb5o3b562bNmid955R5IUGxur8ePHKy4uThMmTNAvv/yiYcOGqV+/fqpataokacKECRoyZIiqVKmirl276sSJE9qwYYOGDRtWoPrGjRun5s2bKzo6Wh6PR5999pk3KAEwG0EFwDX7/PPPVa1atTzLGjRooL1790o6/0TOggUL9Oijj6patWr68MMP1ahRI0lSUFCQEhMT9dhjj6lly5YKCgpS79699fLLL3v3FRcXpzNnzuiVV17RyJEjVblyZf3jH/8ocH3+/v4aPXq0Dh06pMDAQP3973/XggULiuDMARQ3h2VZlt1FALh+ORwOLV68WD179rS7FAClEGNUAACAsQgqAADAWIxRAVCsuLsM4FpwRQUAABiLoAIAAIxFUAEAAMYiqAAAAGMRVAAAgLEIKgAAwFgEFQAAYCyCCgAAMNb/BRF4fInncp3jAAAAAElFTkSuQmCC"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Inference",
   "id": "e70edc36e643819e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T12:12:57.750311Z",
     "start_time": "2024-10-13T12:10:23.657463Z"
    }
   },
   "cell_type": "code",
   "source": "megabyte.generate(sample_x, decode_fn=decode)",
   "id": "c5067e98aebbc674",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIONE:\n",
      "To tell, he longs to see his mouth: thin  oatssdhipg somn mostegae tseufhdstuniarsLmWn tnigptledLsw rnuts ,nmund myewrI swyan hwnrw \n",
      "uog oo  oun sntmhr eore\n",
      "toll teops  'fmrmsmtla ;hbssylti.e\n",
      "whucn dose yauley -oi\n",
      "ent na'er aodniieg.a\n",
      ",otiment  not\n",
      "aoa Cerilt nfbrewdntsa\n",
      ",awhhl ,hwuktlb  otres\n",
      ",id goaasyo  oath -alpaaser lndkt,ii. LTnlr ndwelh raohs\n",
      "\n",
      "ruat  oa hese;tWilt nhwlyo \n",
      "nlwonts  henc.,\n",
      "Bhelhaa,dat,hautto,,mdd mokt see oWe\n",
      "lnn  hanh oh  iclaa dlswreteh af rvsraeo\n",
      ".oBvtnos,fg tnesy,io \n",
      "ale io vhs'a uepen t omhr\n",
      "whoteet a  aotr sluv,\n",
      "O rad olt hosbmert\n",
      "nsver wtel  ow you snensteo snceesI cheor ropln.TNywtlh  aooh\n",
      "mtnre\n",
      "tvls meenwr toasf to rhsoota ehtlgr't\n",
      "msslnpforc: then d\n",
      " regoon aobyyd oun taake  oon dhamh\n",
      "mvlstrpcsaeias \n",
      " fmorhum desian soel afddanei ylur,.E\n",
      "ftr aob eoml nith rsvaxte\n",
      "hfserci ynucbiogsIat\n",
      "\n",
      "heu  dprntsatt\n",
      "e desdeds uho\n",
      "torcelvsswtro govd\n",
      "eibhery oi  todcssoa'i  lone. Bhtm not Ivfr\n",
      "toer eoet  itsefsrotefieitg d aatitgnnyt rnsoaoh;\n",
      "teel tia  eattee  sllunn\n",
      "st treast dfac estencf,Twicg symll,rP instendmMnsslwturd devile Phtnfsugltrawstyi goe\n",
      " teerls mev loae. Orf oectmos  rlgpaase'o,gbttent Toubhyrdnwwatdhd\n",
      "wan  liwe,taards,iuL \n",
      "erg  oyradlsnoss\n",
      "drswrftcisnnsrow  hoso  nleod,naye  tloe  cryaits\n",
      " fdotn soad eum uuleeb; eodes  nwtenl moi\n",
      " ewssowtf giolsn sirh af ever\n",
      " eaotg oo  oor.C\n",
      "Masyer  fnown\n",
      "lteonsa remergisd\n",
      "moss  iaheso-uod snuwshnmst\n",
      "raser  lwektlp  oahhe Eagaent,ygnbly eserti\n",
      "gevtloxs rosaei  uo \n",
      "tuennh\n",
      "nn uhtudai sbinr \n",
      "aumhns,\n",
      "alv soneath ti eojtre thet ou  oanh soadh'  aulh ir Patlenaeee,,atitfnlt, aod sover niee;\n",
      "Frrmmidssrrwm noohfmtnec  faor,hTrobg,taki gaoeeTauye;.aL,,ttntr, f ia \n",
      "eeri hgnosy!sI,pfiltsb\n",
      ",oe  eae un ufse romet Wilhsfait'bnnssm to be comg: audted aoy  oot cfaet:bIui hnm lemdee  atmensfTi\n",
      "ent htterms yftlr  btsrrwwesh  a"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Evaluation",
   "id": "495822436e557079"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T12:12:57.753320Z",
     "start_time": "2024-10-13T12:12:57.751431Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "acd82062c9902c0f",
   "outputs": [],
   "execution_count": 33
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
